{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29cd3d56",
   "metadata": {},
   "source": [
    "# Testare whisper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb4b50",
   "metadata": {},
   "source": [
    "whisper è un modello di **OPENAI**.    \n",
    "Si possono trovare informazioni su: \n",
    "   \n",
    "   - Introduzione a whisper: https://openai.com/index/whisper/\n",
    "\n",
    "   - Pagina github di whisper: https://github.com/openai/whisper?tab=readme-ov-file\n",
    "\n",
    "   - Pagina github di OpenAI: https://github.com/openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8277f1c3",
   "metadata": {},
   "source": [
    "#  Controllare che whisper sia installato"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409f664f",
   "metadata": {},
   "source": [
    "Si utilizza l'environment conda chiamato **whisper**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83e5370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "484a1a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20240930'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Versione di whisper\n",
    "whisper.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05686f6a",
   "metadata": {},
   "source": [
    "# Importare i vari modelli di whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba8b8c0",
   "metadata": {},
   "source": [
    "## Caricare il modello  tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de0ed02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 72.1M/72.1M [00:14<00:00, 5.26MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model_tiny = whisper.load_model(\"tiny\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f86655",
   "metadata": {},
   "source": [
    "## Caricare il modello base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbe5be57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:27<00:00, 5.32MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model_base = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5131832",
   "metadata": {},
   "source": [
    "## Caricare il modello small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11ce3461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/whisper/lib/python3.9/site-packages/whisper/__init__.py:69: UserWarning: /Users/mattia/.cache/whisper/small.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████| 461M/461M [01:37<00:00, 4.97MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model_small = whisper.load_model(\"small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e633da",
   "metadata": {},
   "source": [
    "## Caricare il modello medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35379902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.42G/1.42G [04:53<00:00, 5.20MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model_medium = whisper.load_model(\"medium\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654d9186",
   "metadata": {},
   "source": [
    "## Caricare il modello large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf3049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_large = whisper.load_model(\"large\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d3ee8",
   "metadata": {},
   "source": [
    "## Caricare il modello turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7006673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_turbo = whisper.load_model(\"turbo\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc0512",
   "metadata": {},
   "source": [
    "# Prova di utilizzo di un modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65c0d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e39ce6",
   "metadata": {},
   "source": [
    "### Utilizzo standard (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06766613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/whisper/lib/python3.9/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo di esecuzione: 62.16 secondi\n"
     ]
    }
   ],
   "source": [
    "start_time_cpu = time.time()\n",
    "\n",
    "model_large = whisper.load_model(\"large\") \n",
    "\n",
    "# Specificare il percorso file dell'audio che si vuole tradurre\n",
    "file_audio = \"/Users/mattia/Desktop/Università/Data Science in Python/13) Neural Networks/Data/Audio/Camera Cafe Prima Stagione/Ep. 0 - Sketch Promo.wav\"\n",
    "\n",
    "# Runnare il modello e trasformare l'audio in testo\n",
    "result = model_large.transcribe(file_audio,language=\"it\")\n",
    "\n",
    "end_time_cpu = time.time()\n",
    "print(f\"Tempo di esecuzione: {end_time_cpu - start_time_cpu:.2f} secondi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e2fa51",
   "metadata": {},
   "source": [
    "### Utilizzo GPU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42bade4",
   "metadata": {},
   "source": [
    "Non potrà funzionare, whisper non supporta la **MPS**.\n",
    "Supporta solo le **cuda Nvidia**.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9223beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_mps = time.time()\n",
    "\n",
    "\n",
    "model_large = whisper.load_model(\"base\",device=\"mps\") \n",
    "\n",
    "# Specificare il percorso file dell'audio che si vuole tradurre\n",
    "file_audio = \"/Users/mattia/Desktop/Università/Data Science in Python/13) Neural Networks/Data/Audio/Camera Cafe Prima Stagione/Ep. 0 - Sketch Promo.wav\"\n",
    "\n",
    "# Trasferisci il modello sulla GPU\n",
    "model_large.to(device)\n",
    "\n",
    "# Runnare il modello e trasformare l'audio in testo\n",
    "result = model.transcribe(file_audio,language=\"it\",fp16=True)\n",
    "\n",
    "end_time_mps = time.time()\n",
    "print(f\"Tempo di esecuzione: {end_time_mps - start_time_mps:.2f} secondi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
